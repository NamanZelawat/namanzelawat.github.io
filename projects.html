<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="https://latex.vercel.app/style.css" />
    <title>Naman Zelawat</title>
    <style>
      html {
        scroll-behavior: smooth;
      }
      h1 {
        padding: 20px;
        margin-bottom: 0;
        text-align: center;
      }
      p {
        font-size: 1.2rem;
        color: #111;
        padding: 0;
        margin: 0;
      }
      ul {
        font-size: 1.2rem;
        color: #111;
      }
      body {
        max-width: 800px;
        padding: 1.5rem 0rem;
      }
      /* The main container for the research paper card */
      .latex-card {
        background: #ffffff;
        border: 1px solid #d1d1d1;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
        /* max-width: 600px; */
        width: 100%;
        padding: 2.5rem 3rem;
        color: #333;
        line-height: 1.6;
        border-radius: 4px;
      }
      .nav-bar {
        text-align: center;
        font-family: "Computer Modern", serif; /* Optional: for LaTeX aesthetic */
        font-size: 1.1em;
        margin-top: 0;
      }

      .nav-bar a {
        text-decoration: none;
        color: inherit; /* Keeps it neutral, blends with text */
        padding: 0 0.3em;
        cursor: pointer;
        transition: opacity 0.2s ease;
      }

      .nav-bar a:hover {
        opacity: 0.7; /* Just enough to hint interactivity */
      }
    </style>
  </head>
  <body>
    <div class="latex-card">
      <h1>Code Projects</h1>
      <div class="nav-bar">
        <a href="./index.html">Home</a> |
        <a
          target="_blank"
          rel="noopener"
          href="https://drive.google.com/file/d/1yGv_nPChQUjimdiVe5Q-mv1uab2jZg3X/view?usp=sharing"
          >CV</a
        >
        | <a href="./index.html#experience">Experience</a> |
        <a href="./index.html#education">Education</a> |
        <a href="./blogs.html">Blogs</a>
      </div>

      <h3>Single image reconstruction</h3>
      <hr />
      <p>
        I leveraged the diffusion model Zero123 to effectively generate missing
        perspectives of an object. The reconstruction process utilized six
        different perspectives to perform highly accurate differential
        rendering. A crucial part of the implementation involved a stepwise
        incremental fitting strategy, where the object's silhouette (mask) was
        optimized first, which was then followed by the optimization of the
        object's texture.
      </p>
      <br />
      <img
        src="./assets/project2_collage.jpg"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p>
        <strong>Domain</strong>: Paper implementation, Computer Vision, Deep
        Learning, PyTorch.
      </p>
      <p>
        <strong>Code</strong>:
        <a
          href="https://colab.research.google.com/drive/1bWNai_qXalOOTB-eSAV9EZ33owbQSTTG?usp=sharing"
          >Link</a
        >
      </p>

      <h3>ViT paper implementation using PyTorch</h3>
      <hr />
      <p>
        I implemented the Vision Transformer (ViT) architecture from scratch,
        visualizing the embedding creation process and training the model on the
        Food-101 dataset for image classification. To further enhance
        performance, I incorporated transfer learning by leveraging pretrained
        weights from PyTorch models, which significantly improved the overall
        accuracy.
      </p>
      <br />
      <img
        src="./assets/transformer.png"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p>
        <strong>Domain</strong>: Paper implementation, Computer Vision, Deep
        Learning, PyTorch.
      </p>
      <p>
        <strong>Code</strong>:
        <a
          href="https://github.com/NamanZelawat/Gym/blob/master/pytorch/paper_replication.ipynb"
          >Link</a
        >
      </p>

      <h3>Textured differential rendering</h3>
      <hr />
      <p>
        This project involved using PyTorch3D to deform an initial spherical
        source mesh into the shape of a target cow mesh. The mesh fitting was
        achieved by performing differential rendering across 20 different views.
        To ensure highly accurate and smooth reconstruction, the optimization
        incorporated a combined loss function utilizing RGB, silhouette,
        Laplacian, Edge, and Normal loss components.
      </p>
      <br />
      <img
        src="./assets/project1_collage.jpg"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p>
        <strong>Domain</strong>: Paper implementation, Computer Vision, Deep
        Learning, PyTorch.
      </p>
      <p>
        <strong>Code</strong>:
        <a
          href="https://nbviewer.org/github/NamanZelawat/3D_ML/blob/master/pytorch3d_textured_mesh.ipynb"
          >Link</a
        >
      </p>

      <h3>Transfer learning using PyTorch</h3>
      <hr />
      <p>
        I utilized pretrained EfficientNet-B0 weights to classify specific
        subcategories of the Food-101 dataset, testing the modelâ€™s
        generalization on real-world data beyond the test set. To streamline the
        workflow, I developed custom wrappers that simplified data preparation,
        training, evaluation, and visualization, making the experimentation
        process more efficient and reproducible.
      </p>
      <br />
      <img
        src="./assets/transfer.png"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p>
        <strong>Domain</strong>: Transfer learning, Computer Vision, Deep
        Learning, PyTorch.
      </p>
      <p>
        <strong>Code</strong>:
        <a
          href="https://github.com/NamanZelawat/Gym/blob/master/pytorch/transfer_learning.ipynb"
          >Link</a
        >
      </p>

      <h3>Fashion MNIST solution in PyTorch</h3>
      <hr />
      <p>
        I worked on predictions using the FashionMNIST dataset, modularizing the
        code to simplify training and testing across three different models. The
        implementation was designed to be device-agnostic, ensuring
        compatibility across CPUs and GPUs, and included detailed time analysis
        for both training and testing phases.
      </p>
      <br />
      <img
        src="./assets/fashion.png"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p><strong>Domain</strong>: Deep Learning, PyTorch.</p>
      <p>
        <strong>Code</strong>:
        <a
          href="https://github.com/NamanZelawat/Gym/blob/master/pytorch/CNN_computer_vision.ipynb"
          >Link</a
        >
      </p>

      <h3>Tic-Tac-Toe</h3>
      <hr />
      <p>
        Adversarial tic-tac-toe implementation using minimax algorithm in C++.
      </p>
      <br />
      <img
        src="./assets/tictactoe.png"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p><strong>Domain</strong>: Artificial intelligence, Algorithm.</p>
      <p>
        <strong>Code</strong>:
        <a href="https://github.com/NamanZelawat/Tic-tac-toe">Link</a>
      </p>
      <br />
      <h1>Graphics Projects</h1>
      <h3>Interplanetary vehicle 2708</h3>
      <hr />
      <p>
        A star wars inspired short film made using Blender. The film showcases a
        futuristic interplanetary vehicle navigating through space, passing
        nearby a planet.
      </p>
      <br />
      <img
        src="./assets/interplanetary_vehicle.png"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p>
        <strong>Domain</strong>: Short Film, 3D graphics, Blender, Animation
      </p>
      <p>
        <strong>Source:</strong>:
        <a href="https://www.youtube.com/watch?v=YncCDqnQvxs">Link</a>
      </p>
      <h3>Cannon animation</h3>
      <hr />
      <p>
        A small cannon model made using Blender. The model showcases basic use
        of graph editor to animate the cannon firing.
      </p>
      <br />
      <img
        src="./assets/cannon.png"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p>
        <strong>Domain</strong>: 3D graphics, Graph editor, Blender, Animation
      </p>
      <p>
        <strong>Source:</strong>:
        <a href="https://www.youtube.com/watch?v=FCos4O5gmf8">Link</a>
      </p>
    </div>
  </body>
</html>
