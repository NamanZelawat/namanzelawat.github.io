<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="https://latex.vercel.app/style.css" />
    <title>Naman Zelawat</title>
    <style>
      html {
        scroll-behavior: smooth;
      }
      h1 {
        padding: 20px;
        margin-bottom: 0;
      }
      p {
        font-size: 1.2rem;
        color: #111;
        padding: 0;
        margin: 0;
      }
      ul {
        font-size: 1.2rem;
        color: #111;
      }
      body {
        max-width: 800px;
        padding: 1.5rem 0rem;
      }
      /* The main container for the research paper card */
      .latex-card {
        background: #ffffff;
        border: 1px solid #d1d1d1;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
        /* max-width: 600px; */
        width: 100%;
        padding: 2.5rem 3rem;
        color: #333;
        line-height: 1.6;
        border-radius: 4px;
      }
    </style>
  </head>
  <body>
    <div class="latex-card">
      <h1>Projects</h1>

      <h3>ViT paper implementation using PyTorch</h3>
      <hr />
      <p>
        I implemented the Vision Transformer (ViT) architecture from scratch,
        visualizing the embedding creation process and training the model on the
        Food-101 dataset for image classification. To further enhance
        performance, I incorporated transfer learning by leveraging pretrained
        weights from PyTorch models, which significantly improved the overall
        accuracy.
      </p>
      <br />
      <img
        src="./assets/transformer.png"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p>
        <strong>Domain</strong>: Paper implementation, Computer Vision, Deep
        Learning, PyTorch.
      </p>
      <p>
        <strong>Code</strong>:
        <a
          href="https://github.com/NamanZelawat/Gym/blob/master/pytorch/paper_replication.ipynb"
          >Link</a
        >
      </p>

      <h3>Transfer learning using PyTorch</h3>
      <hr />
      <p>
        I utilized pretrained EfficientNet-B0 weights to classify specific
        subcategories of the Food-101 dataset, testing the modelâ€™s
        generalization on real-world data beyond the test set. To streamline the
        workflow, I developed custom wrappers that simplified data preparation,
        training, evaluation, and visualization, making the experimentation
        process more efficient and reproducible.
      </p>
      <br />
      <img
        src="./assets/transfer.png"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p>
        <strong>Domain</strong>: Transfer learning, Computer Vision, Deep
        Learning, PyTorch.
      </p>
      <p>
        <strong>Code</strong>:
        <a
          href="https://github.com/NamanZelawat/Gym/blob/master/pytorch/transfer_learning.ipynb"
          >Link</a
        >
      </p>

      <h3>Fashion MNIST solution in PyTorch</h3>
      <hr />
      <p>
        I worked on predictions using the FashionMNIST dataset, modularizing the
        code to simplify training and testing across three different models. The
        implementation was designed to be device-agnostic, ensuring
        compatibility across CPUs and GPUs, and included detailed time analysis
        for both training and testing phases.
      </p>
      <br />
      <img
        src="./assets/fashion.png"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p><strong>Domain</strong>: Deep Learning, PyTorch.</p>
      <p>
        <strong>Code</strong>:
        <a
          href="https://github.com/NamanZelawat/Gym/blob/master/pytorch/CNN_computer_vision.ipynb"
          >Link</a
        >
      </p>

      <h3>Tic-Tac-Toe</h3>
      <hr />
      <p>
        Adversarial tic-tac-toe implementation using minimax algorithm in C++.
      </p>
      <br />
      <img
        src="./assets/tictactoe.png"
        alt="Image patches"
        ,
        width="300"
        style="display: block; margin-left: auto; margin-right: auto"
      />
      <br />
      <p><strong>Domain</strong>: Artificial intelligence, Algorithm.</p>
      <p>
        <strong>Code</strong>:
        <a href="https://github.com/NamanZelawat/Tic-tac-toe">Link</a>
      </p>
    </div>
  </body>
</html>
